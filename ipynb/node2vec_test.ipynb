{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g = nx.read_gpickle(\"github.gpickle.2\")\n",
    "#g = nx.read_gexf('les-miserables.gexf')\n",
    "#nx.write_graphml(g, \"github.graphml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      "Type: DiGraph\n",
      "Number of nodes: 96833\n",
      "Number of edges: 233089\n",
      "Average in degree:   2.4071\n",
      "Average out degree:   2.4071\n"
     ]
    }
   ],
   "source": [
    "print nx.info(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_w(g):\n",
    "    for edge in g.edges():\n",
    "        g[edge[0]][edge[1]]['weight'] = 1\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D = True\n",
    "P = 1\n",
    "#Return hyperparameter. Default is 1\n",
    "Q = 1\n",
    "#Inout hyperparameter. Default is 1.\n",
    "NW = 10\n",
    "#Number of walks per source. Default is 40\n",
    "WL = 40\n",
    "#Length of walk per source. Default is 10.\n",
    "WORKERS = 8\n",
    "#'Number of parallel workers. Default is 8.\n",
    "WIN_SIZE = 10\n",
    "#Context size for optimization. Default is 10.\n",
    "ITER = 20\n",
    "#Number of epochs in SGD\n",
    "DIM = 128\n",
    "#Number of dimensions. Default is 128.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walk iteration:\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n"
     ]
    }
   ],
   "source": [
    "nx_G = add_w(g)\n",
    "\n",
    "G = Graph(nx_G, D, P, Q)\n",
    "G.preprocess_transition_probs()\n",
    "walks = G.simulate_walks(NW, WL)\n",
    "#learn_embeddings(walks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def learn_embeddings(walks):\n",
    "    '''\n",
    "    Learn embeddings by optimizing the Skipgram objective using SGD.\n",
    "    '''\n",
    "    walks = [map(str, walk) for walk in walks]\n",
    "    model = Word2Vec(walks, size=DIM, window=WIN_SIZE, min_count=0, workers=WORKERS, iter=ITER)\n",
    "    return model\n",
    "\n",
    "model = learn_embeddings(walks)\n",
    "model.save_word2vec_format(\"output.emb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0\n",
      "['cleditor(repo)']\n",
      "\n",
      "Cluster 1\n",
      "['Mining-the-Social-Web(repo)']\n",
      "\n",
      "Cluster 2\n",
      "['tianhaocto(user)']\n",
      "\n",
      "Cluster 3\n",
      "['oz(repo)', 'AndroidLibs(repo)', 'ImageGalleryView(repo)', 'walt(repo)', 'clappr-p2phls-plugin(repo)', 'django-admin-enhancer(repo)', 'angular-moment-picker(repo)', 'ng-notify(repo)', 'nist-testvectors(repo)', 'linthub-demo(repo)', 'php-kmeans(repo)', 'paulbersch(user)']\n",
      "\n",
      "Cluster 4\n",
      "['appmetrics(repo)', 'kawaldesa(repo)', 'pencil(repo)', 'frash(repo)', 'ctabustracker(repo)', 'BrowserTV(repo)', 'ncdu-s3(repo)', 'DatabaseCommands(repo)', 'gcli(repo)', 'retire(repo)', 'endless-runner(repo)', 'websockets-talk(repo)', 'ansi(repo)']\n",
      "\n",
      "Cluster 5\n",
      "['mtfelix(user)']\n",
      "\n",
      "Cluster 6\n",
      "['r-checker(repo)', 'HySubmitTransitionObjective-C(repo)']\n",
      "\n",
      "Cluster 7\n",
      "['mdm-server(repo)', 'ruby-pocketsphinx-server(repo)', 'htop(repo)', 'EmbedAssets(repo)', 'vim-multiple-cursors(repo)', 'py-nilsimsa(repo)']\n",
      "\n",
      "Cluster 8\n",
      "['LazyPHP(repo)', 'riscv-sodor(repo)']\n",
      "\n",
      "Cluster 9\n",
      "['RolandAdorjani(user)']\n",
      "\n",
      "Cluster 10\n",
      "['lightsOn(repo)', 'CiphSafe(repo)', 'serverless-survey-forms(repo)', 'gpslogger(repo)']\n",
      "\n",
      "Cluster 11\n",
      "['WP-Job-Manager(repo)', 'violin(repo)', 'Smooth(repo)', 'BMXSwipableCell(repo)', 'michaelmonteleone.net(repo)', 'primefaces-cookbook(repo)', 'jstz(repo)', 'carrierwave(repo)', 'mxnet-memonger(repo)']\n",
      "\n",
      "Cluster 12\n",
      "['stock-exchange(repo)', 'avro(repo)', 'sequelize(repo)', 'ZenCoding-Python(repo)', 'go-geoindex(repo)']\n",
      "\n",
      "Cluster 13\n",
      "['shine.js(repo)', 'ranwhen(repo)', 'code-standards(repo)', 'JUCEAmalgam(repo)', 'deploy-aws(repo)', 'real-world-rails(repo)', 'hts-python(repo)', 'django-balanced(repo)', 'fsui(repo)', 'DODropletManager-OSX(repo)']\n",
      "\n",
      "Cluster 14\n",
      "['pythonscripts(repo)', 'Ara(repo)', 'cop21(repo)', 'Pardus-Bulut(repo)', 'openshift-nodebb(repo)', 'turbograft(repo)', 'modelq(repo)', 'play-api-rest-seed(repo)', 'qmq(repo)', 'TweetRain(repo)', 'mysandbox(repo)', 'cssshrink(repo)', 'aspnet-docker(repo)', 'fabfiles(repo)', 'tracklytics(repo)', 'present(repo)', 'graphchiDB-scala(repo)', 'parties(repo)']\n",
      "\n",
      "Cluster 15\n",
      "['impress.js(repo)']\n",
      "\n",
      "Cluster 16\n",
      "['owncloud-gallery(repo)', 'netshPacketCap(repo)', 'kinesis-poster-worker(repo)', 'jser(repo)', 'NovixPivotJS(repo)', 'PHP-Xcode-Autocomplete(repo)', 'donations(repo)', 'electron-remote(repo)', 'NinjaCopy(repo)', 'react-jsonschema-form(repo)', 'captainwebhook(repo)', 'jrae(repo)', 'emberreddit-old(repo)', 'vogl(repo)', 'factory-go(repo)', 'potionstore(repo)', 'O365-WebApp-MultiTenant(repo)', 'SwiftGraphics(repo)', 'neovim-qt(repo)', 'rails_stats(repo)', 'sparql-table-viewer(repo)', 'vim-togglecursor(repo)', 'lucumr(repo)', '2011-slides(repo)', 'foos(repo)', 'ReactNativeHackerNews(repo)', 'ascii_cam(repo)', 'pikater(repo)', 'pure-python-otr(repo)', 'Swift-AI(repo)', 'poly(repo)', 'rest-with-scala(repo)', 'iGeo(repo)', 'checkipfw(repo)', 'ruby-fann(repo)', 'YoutubeCraawler(repo)', 'pentest-machine(repo)', 'semistandard(repo)', 'MHFacebookImageViewer(repo)', 'dots_for_microarrays(repo)']\n",
      "\n",
      "Cluster 17\n",
      "['flashBS(repo)', 'octopi(repo)', 'python-dyndnsc(repo)']\n",
      "\n",
      "Cluster 18\n",
      "['howistart.org(repo)', 'andbase(repo)', 'TRZSlideLicenseViewController(repo)', 'otphp(repo)', 'TechnicalAnalysisFramework(repo)', 'Diver(repo)', 'Noisy(repo)', 'django-cleanup(repo)']\n",
      "\n",
      "Cluster 19\n",
      "['amazon-dsstne(repo)', 'fantasy_bball_research(repo)', 'pithy(repo)', 'cropman(repo)']\n",
      "CPU times: user 9h 40min 30s, sys: 9.04 s, total: 9h 40min 39s\n",
      "Wall time: 9h 41min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "word_vectors = model.syn0\n",
    "num_clusters = word_vectors.shape[0] / 5\n",
    "\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n",
    "\n",
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,20):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.most_similar(positive=['d3(repo)', 'jquery(repo)'], negative=['EthereumContracts(repo)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print model.similarity('d3(repo)', 'jquery(repo)')\n",
    "#print model.similarity('Big_Data_Resources(repo)', 'jquery(repo)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('scipher(repo)', 0.3856104612350464),\n",
       " ('go-geoindex(repo)', 0.3782304525375366),\n",
       " ('cronos(repo)', 0.3677201271057129),\n",
       " ('sphinxcontrib.datatemplates(repo)', 0.3663907051086426),\n",
       " ('flickering(repo)', 0.34900200366973877),\n",
       " ('inline(repo)', 0.33638596534729004),\n",
       " ('Hermite-resize(repo)', 0.3334677815437317),\n",
       " ('smarty-renderer(repo)', 0.3314046263694763),\n",
       " ('crawl-extract(repo)', 0.3293003737926483),\n",
       " ('node-browserstack(repo)', 0.3218599557876587)]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar('avro(repo)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sp = nx.all_shortest_paths(g,source='Dumbris(user)',target='titan(repo)')\n",
    "print([p for p in sp])\n",
    "#nx.astar_path(g,source='davni(user)',target='ekgren(user)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.similar_by_vector(model['Dumbris(user)'] + model['jfenton(user)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "class Graph():\n",
    "\tdef __init__(self, nx_G, is_directed, p, q):\n",
    "\t\tself.G = nx_G\n",
    "\t\tself.is_directed = is_directed\n",
    "\t\tself.p = p\n",
    "\t\tself.q = q\n",
    "\n",
    "\tdef node2vec_walk(self, walk_length, start_node):\n",
    "\t\t'''\n",
    "\t\tSimulate a random walk starting from start node.\n",
    "\t\t'''\n",
    "\t\tG = self.G\n",
    "\t\talias_nodes = self.alias_nodes\n",
    "\t\talias_edges = self.alias_edges\n",
    "\n",
    "\t\twalk = [start_node]\n",
    "\n",
    "\t\twhile len(walk) < walk_length:\n",
    "\t\t\tcur = walk[-1]\n",
    "\t\t\tcur_nbrs = sorted(G.neighbors(cur))\n",
    "\t\t\tif len(cur_nbrs) > 0:\n",
    "\t\t\t\tif len(walk) == 1:\n",
    "\t\t\t\t\twalk.append(cur_nbrs[alias_draw(alias_nodes[cur][0], alias_nodes[cur][1])])\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tprev = walk[-2]\n",
    "\t\t\t\t\tnext = cur_nbrs[alias_draw(alias_edges[(prev, cur)][0], \n",
    "\t\t\t\t\t\talias_edges[(prev, cur)][1])]\n",
    "\t\t\t\t\twalk.append(next)\n",
    "\t\t\telse:\n",
    "\t\t\t\tbreak\n",
    "\n",
    "\t\treturn walk\n",
    "\n",
    "\tdef simulate_walks(self, num_walks, walk_length):\n",
    "\t\t'''\n",
    "\t\tRepeatedly simulate random walks from each node.\n",
    "\t\t'''\n",
    "\t\tG = self.G\n",
    "\t\twalks = []\n",
    "\t\tnodes = list(G.nodes())\n",
    "\t\tprint 'Walk iteration:'\n",
    "\t\tfor walk_iter in range(num_walks):\n",
    "\t\t\tprint str(walk_iter+1), '/', str(num_walks)\n",
    "\t\t\trandom.shuffle(nodes)\n",
    "\t\t\tfor node in nodes:\n",
    "\t\t\t\twalks.append(self.node2vec_walk(walk_length=walk_length, start_node=node))\n",
    "\n",
    "\t\treturn walks\n",
    "\n",
    "\tdef get_alias_edge(self, src, dst):\n",
    "\t\t'''\n",
    "\t\tGet the alias edge setup lists for a given edge.\n",
    "\t\t'''\n",
    "\t\tG = self.G\n",
    "\t\tp = self.p\n",
    "\t\tq = self.q\n",
    "\n",
    "\t\tunnormalized_probs = []\n",
    "\t\tfor dst_nbr in sorted(G.neighbors(dst)):\n",
    "\t\t\tif dst_nbr == src:\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight']/p)\n",
    "\t\t\telif G.has_edge(dst_nbr, src):\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight'])\n",
    "\t\t\telse:\n",
    "\t\t\t\tunnormalized_probs.append(G[dst][dst_nbr]['weight']/q)\n",
    "\t\tnorm_const = sum(unnormalized_probs)\n",
    "\t\tnormalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "\n",
    "\t\treturn alias_setup(normalized_probs)\n",
    "\n",
    "\tdef preprocess_transition_probs(self):\n",
    "\t\t'''\n",
    "\t\tPreprocessing of transition probabilities for guiding the random walks.\n",
    "\t\t'''\n",
    "\t\tG = self.G\n",
    "\t\tis_directed = self.is_directed\n",
    "\n",
    "\t\talias_nodes = {}\n",
    "\t\tfor node in G.nodes():\n",
    "\t\t\tunnormalized_probs = [G[node][nbr]['weight'] for nbr in sorted(G.neighbors(node))]\n",
    "\t\t\tnorm_const = sum(unnormalized_probs)\n",
    "\t\t\tnormalized_probs =  [float(u_prob)/norm_const for u_prob in unnormalized_probs]\n",
    "\t\t\talias_nodes[node] = alias_setup(normalized_probs)\n",
    "\n",
    "\t\talias_edges = {}\n",
    "\t\ttriads = {}\n",
    "\n",
    "\t\tif is_directed:\n",
    "\t\t\tfor edge in G.edges():\n",
    "\t\t\t\talias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
    "\t\telse:\n",
    "\t\t\tfor edge in G.edges():\n",
    "\t\t\t\talias_edges[edge] = self.get_alias_edge(edge[0], edge[1])\n",
    "\t\t\t\talias_edges[(edge[1], edge[0])] = self.get_alias_edge(edge[1], edge[0])\n",
    "\n",
    "\t\tself.alias_nodes = alias_nodes\n",
    "\t\tself.alias_edges = alias_edges\n",
    "\n",
    "\t\treturn\n",
    "\n",
    "\n",
    "def alias_setup(probs):\n",
    "\t'''\n",
    "\tCompute utility lists for non-uniform sampling from discrete distributions.\n",
    "\tRefer to https://hips.seas.harvard.edu/blog/2013/03/03/the-alias-method-efficient-sampling-with-many-discrete-outcomes/\n",
    "\tfor details\n",
    "\t'''\n",
    "\tK = len(probs)\n",
    "\tq = np.zeros(K)\n",
    "\tJ = np.zeros(K, dtype=np.int)\n",
    "\n",
    "\tsmaller = []\n",
    "\tlarger = []\n",
    "\tfor kk, prob in enumerate(probs):\n",
    "\t    q[kk] = K*prob\n",
    "\t    if q[kk] < 1.0:\n",
    "\t        smaller.append(kk)\n",
    "\t    else:\n",
    "\t        larger.append(kk)\n",
    "\n",
    "\twhile len(smaller) > 0 and len(larger) > 0:\n",
    "\t    small = smaller.pop()\n",
    "\t    large = larger.pop()\n",
    "\n",
    "\t    J[small] = large\n",
    "\t    q[large] = q[large] + q[small] - 1.0\n",
    "\t    if q[large] < 1.0:\n",
    "\t        smaller.append(large)\n",
    "\t    else:\n",
    "\t        larger.append(large)\n",
    "\n",
    "\treturn J, q\n",
    "\n",
    "def alias_draw(J, q):\n",
    "\t'''\n",
    "\tDraw sample from a non-uniform discrete distribution using alias sampling.\n",
    "\t'''\n",
    "\tK = len(J)\n",
    "\n",
    "\tkk = int(np.floor(np.random.rand()*K))\n",
    "\tif np.random.rand() < q[kk]:\n",
    "\t    return kk\n",
    "\telse:\n",
    "\t    return J[kk]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "pySpark (Spark 1.6.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "notify_time": "10",
  "widgets": {
   "state": {},
   "version": "2.0.0-dev"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
